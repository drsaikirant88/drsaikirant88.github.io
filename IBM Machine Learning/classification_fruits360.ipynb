{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a36546-2940-4797-8e39-d9212e18b608",
   "metadata": {},
   "source": [
    "# Deep Learning - Image Classification\n",
    "\n",
    "## Objective\n",
    "The goal of this project is to build a deep learning model based on a pervious notebook on [training CIFAR10 dataset](https://github.com/drsaikirant88/drsaikirant88.github.io/blob/main/IBM%20Machine%20Learning/classification_multigpu.ipynb). This is a step-up from the previous work where the model was trained to identify 10 classes. Here the model will be trained on Fruits360 dataset with a goal to correctly classify fruits and vegetables in 131 different classes. The model will be built from scratch but based on WideResNet implementation as in the previous notebook. The current model is trained on Texas Advanced Computing Center's Frontera HPC. The current training is run on 1 node with 4 Nvidia Quadro RTX 5000 GPUs.\n",
    "\n",
    "<img src=\"nvidiasmi_tacc.jpg\" width=\"600\">\n",
    "\n",
    "[Horovod](https://horovod.ai/), a deep learning framework for TensorFlow will be used to scale training to multiple GPUs. Since this is run using existing MPI (i.e. requiring mpirun), the output from training is parsed to this notebook.\n",
    "\n",
    "## Dataset\n",
    "The [Fruits360 dataset](https://www.kaggle.com/moltean/fruits) consists of 131 types of fruits and vegetables. Same fruit but of a different variety is also represented by a different class. The dataset consists of images of 100x100 pixels.\n",
    "\n",
    "The following fruits and are included:\n",
    "<br>Apples (different varieties: Crimson Snow, Golden, Golden-Red, Granny Smith, Pink Lady, Red, Red Delicious), Apricot, Avocado, Avocado ripe, Banana (Yellow, Red, Lady Finger), Beetroot Red, Blueberry, Cactus fruit, Cantaloupe (2 varieties), Carambula, Cauliflower, Cherry (different varieties, Rainier), Cherry Wax (Yellow, Red, Black), Chestnut, Clementine, Cocos, Corn (with husk), Cucumber (ripened), Dates, Eggplant, Fig, Ginger Root, Granadilla, Grape (Blue, Pink, White (different varieties)), Grapefruit (Pink, White), Guava, Hazelnut, Huckleberry, Kiwi, Kaki, Kohlrabi, Kumsquats, Lemon (normal, Meyer), Lime, Lychee, Mandarine, Mango (Green, Red), Mangostan, Maracuja, Melon Piel de Sapo, Mulberry, Nectarine (Regular, Flat), Nut (Forest, Pecan), Onion (Red, White), Orange, Papaya, Passion fruit, Peach (different varieties), Pepino, Pear (different varieties, Abate, Forelle, Kaiser, Monster, Red, Stone, Williams), Pepper (Red, Green, Orange, Yellow), Physalis (normal, with Husk), Pineapple (normal, Mini), Pitahaya Red, Plum (different varieties), Pomegranate, Pomelo Sweetie, Potato (Red, Sweet, White), Quince, Rambutan, Raspberry, Redcurrant, Salak, Strawberry (normal, Wedge), Tamarillo, Tangelo, Tomato (different varieties, Maroon, Cherry Red, Yellow, not ripened, Heart), Walnut, Watermelon.\n",
    "\n",
    "The total number of images: 90483\n",
    "<br>Training set size: 67692 images (one fruit or vegetable per image)\n",
    "<br>Test set size: 22688 images (one fruit or vegetable per image)\n",
    "<br>The number of classes: 131 (fruits and vegetables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c63d4cba-1c94-4ea4-8516-7be4229e63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import csv\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense, Add, Activation, Dropout, MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "import horovod.tensorflow.keras as hvd\n",
    "from horovod.tensorflow.keras.callbacks import LearningRateWarmupCallback, BroadcastGlobalVariablesCallback, MetricAverageCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5363c-836a-4d05-ad74-66b968400f55",
   "metadata": {},
   "source": [
    "### Horovod - processing on multi GPUs\n",
    "Initialize Horovod and pin it to a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ccf0f3-7056-4bc2-bff7-4389344f1c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Horovod\n",
    "hvd.init()\n",
    "\n",
    "# Pin to a GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[hvd.local_rank()], True)\n",
    "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a2c75-8348-4ba5-bd2d-04437c80f43b",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f3691-42ba-41ab-9cfb-9849a296f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 64\n",
    "epochs     = 80\n",
    "\n",
    "warmup_epochs = 5    # No of epochs for which base learning rate will be used\n",
    "momentum = 0.9       # Momentum for Stochastic Gradient Descent\n",
    "\n",
    "base_learning_rate = 0.1 # Learning rate for 1 GPU\n",
    "\n",
    "train_target = 0.8 # Training target accuracy\n",
    "val_target   = 0.8 # Validation target accuracy\n",
    "\n",
    "datapath = '/scratch1/05802/tharimen/data/fruits360'\n",
    "\n",
    "savemodel = '/scratch1/05802/tharimen/dlmodels/model_fruits360'\n",
    "\n",
    "num_classes = 131\n",
    "\n",
    "# Set verbose based on GPU rank\n",
    "if hvd.rank() == 0:\n",
    "    verbose = 1\n",
    "else:\n",
    "    verbose = 0 # prints total time\n",
    "\n",
    "\n",
    "# Dataset is in organized in folders\n",
    "# ImageGenerator class will be used\n",
    "# to read data, resize, and rescale images\n",
    "\n",
    "# Resize image dimensions\n",
    "img_rows, img_cols = 100, 100\n",
    "\n",
    "# Rescale images to 0 - 1\n",
    "rescale = 1./255.\n",
    "\n",
    "# Reformat to Keras friendly format\n",
    "input_shape = (3, img_rows, img_cols) if K.image_data_format() == 'channels_first' else (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5166c15-61f8-4ec8-a9d4-931d5c30a40d",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a5ef6-5716-4cf9-abef-6b0b516217ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator for training\n",
    "# This will be used to perform additional processing on the images that\n",
    "# will help with training\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "                featurewise_center=False,            # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,             # set each sample mean to 0\n",
    "                featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                zca_whitening=False,                 # apply ZCA whitening\n",
    "                zca_epsilon=1e-06,                   # epsilon for ZCA whitening\n",
    "                rotation_range=0,                    # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                width_shift_range=0.1,               # randomly shift images horizontally (fraction of total width)\n",
    "                height_shift_range=0.1,              # randomly shift images vertically (fraction of total height)\n",
    "                shear_range=0.,                      # set range for random shear\n",
    "                zoom_range=0.,                       # set range for random zoom\n",
    "                channel_shift_range=0.,              # set range for random channel shifts\n",
    "                fill_mode='nearest',                 # set mode for filling points outside the input boundaries\n",
    "                cval=0.,                             # value used for fill_mode = \"constant\"\n",
    "                horizontal_flip=True,                # randomly flip images\n",
    "                vertical_flip=False,                 # randomly flip images\n",
    "                rescale=rescale,                     # set rescaling factor (applied before any other transformation)\n",
    "                preprocessing_function=None,         # set function that will be applied on each input\n",
    "                data_format=None,                    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                validation_split=0.0)                # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "\n",
    "# Create training iterator\n",
    "train_iter = train_datagen.flow_from_directory(join(datapath, 'train'),\n",
    "                                               target_size=(img_rows, img_cols),\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',\n",
    "                                               shuffle=False,\n",
    "                                               seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f73441-a176-476a-85c4-fdf6fcef68a9",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57e418-229b-4c39-afd8-72151b7937e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator for test and validation\n",
    "# This will be used to perform additional processing on the images that\n",
    "# will help with training\n",
    "test_datagen = image.ImageDataGenerator(\n",
    "                featurewise_center=False,            # set input mean to 0 over the dataset\n",
    "                samplewise_center=False,             # set each sample mean to 0\n",
    "                featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "                samplewise_std_normalization=False,  # divide each input by its std\n",
    "                rescale=rescale)                     # set rescaling factor (applied before any other transformation)\n",
    "\n",
    "# Test iterator\n",
    "test_iter = test_datagen.flow_from_directory(join(datapath, 'test'),\n",
    "                                             target_size=(img_rows, img_cols),\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode='categorical',\n",
    "                                             shuffle=False,\n",
    "                                             seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82f696-27cb-431e-bd9b-794e8013f5aa",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "A deep learning model is built based on the WideResNet model with depth of 20 and width of 131. The model is built with the functional API of Keras. Since the model will be run on 4 GPUs, these cells will be used in a separate python script and run with mpirun.\n",
    "\n",
    "The WideResNet implementation is based on https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/applications/wide_resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cee89d-139b-4ca3-aeba-5a6748b29fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Generate Model\n",
    "def create_model(input_shape, baselr, momentum):\n",
    "    \n",
    "    # Helper functions - convolution with Batch Normalization\n",
    "    def conv_batchnorm(x, conv_size, channel_axis):\n",
    "        \n",
    "        x = Conv2D(filters=conv_size, kernel_size=(3,3), padding='same')(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    # Convolution block - calls conv_batchnorm and adds drop out\n",
    "    def conv_block(x, conv_size, channel_axis, scale_input = False):\n",
    "        x_0 = x\n",
    "        if scale_input:\n",
    "            x_0 = Conv2D(conv_size, (1, 1), activation='linear', padding='same')(x_0)\n",
    "\n",
    "        x = conv_batchnorm(x, conv_size, channel_axis)\n",
    "        x = Dropout(0.01)(x)\n",
    "        x = conv_batchnorm(x, conv_size, channel_axis)\n",
    "        x = Add()([x_0, x])\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # Input\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Channel axis\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    \n",
    "    # Model - 1st layer\n",
    "    x = conv_batchnorm(inputs, 20, channel_axis)\n",
    "    \n",
    "    # 1st conv block with and without scaling\n",
    "    x = conv_block(x, 160, channel_axis, True)\n",
    "    x = conv_block(x, 160, channel_axis)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 2nd conv block\n",
    "    x = conv_block(x, 320, channel_axis, True)\n",
    "    x = conv_block(x, 320, channel_axis)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 3rd conv block\n",
    "    x = conv_block(x, 640, channel_axis, True)\n",
    "    x = conv_block(x, 640, channel_axis)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    # 4th conv block\n",
    "    x = conv_block(x, 1280, channel_axis, True)\n",
    "    x = conv_block(x, 1280, channel_axis)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "  \n",
    "    # Output dense layer of num classes with softmax activation\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    opt = SGD(lr=baselr, momentum=momentum)\n",
    "\n",
    "    # Wrap optimizer in Horovod distributed optimizer\n",
    "    opt = hvd.DistributedOptimizer(opt)\n",
    "    \n",
    "    # Compile\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba714e-9599-497d-9f2b-18bda883b26f",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597df54d-e014-4195-acde-cd499fc2fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Callbacks\n",
    "# Callbacks for printing total time and for early stopping\n",
    "# For early stopping, train and validation targets are used\n",
    "# For the first run, training will be run for all epochs\n",
    "# and for the subsequent run, training will be stopped at a\n",
    "# set value of validation and training target accuracy\n",
    "\n",
    "# Total time\n",
    "class PrintTotalTime(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.start_time = time()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        elapsed_time = round(time() - self.start_time, 2)\n",
    "        print(\"Elapsed training time through epoch {}: {}\".format(epoch+1, elapsed_time))\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        total_time = round(time() - self.start_time, 2)\n",
    "        print(\"Total training time: {}\".format(total_time)) \n",
    "\n",
    "class PrintThroughput(Callback):\n",
    "    def __init__(self, total_images=0):\n",
    "        self.total_images = total_images\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        epoch_time = time() - self.epoch_start_time\n",
    "        images_per_sec = round(self.total_images / epoch_time, 2)\n",
    "        print('Images/sec: {}'.format(images_per_sec))\n",
    "\n",
    "# Stop accuracy\n",
    "class StopAtAccuracy(Callback):\n",
    "    def __init__(self, train_target=0.75, val_target=0.25, patience=2, verbose=0):\n",
    "        self.train_target = train_target\n",
    "        self.val_target = val_target\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.stopped_epoch = 0\n",
    "        self.met_train_target = 0\n",
    "        self.met_val_target = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('accuracy') > self.train_target:\n",
    "            self.met_train_target += 1\n",
    "        else:\n",
    "            self.met_train_target = 0\n",
    "            \n",
    "        if logs.get('val_accuracy') > self.val_target:\n",
    "            self.met_val_target += 1\n",
    "        else:\n",
    "            self.met_val_target = 0\n",
    "\n",
    "        if self.met_train_target >= self.patience and self.met_val_target >= self.patience:\n",
    "            self.stopped_epoch = epoch\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and verbose == 1:\n",
    "            print('Early stopping after epoch {}. Training accuracy target ({}) and validation accuracy target ({}) met.'.format(self.stopped_epoch + 1, self.train_target, self.val_target))\n",
    "\n",
    "# Save training data\n",
    "class SaveTrainingData(Callback):\n",
    "    def __init__(self, data_filepath=''):\n",
    "        self.data_filepath = data_filepath\n",
    "\n",
    "    def on_train_begin(self, logs=None):       \n",
    "        file = open(self.data_filepath, 'w', newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['time', 'val_accuracy'])\n",
    "        writer.writerow([0.0, 0.0])\n",
    "        file.close()  \n",
    "\n",
    "        self.train_start_time = time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        total_time = time() - self.train_start_time\n",
    "        file = open(self.data_filepath, 'a')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([round(total_time,1), round(logs['val_accuracy'], 4)])\n",
    "        file.close()\n",
    "\n",
    "# Learning rate scheduler\n",
    "# Base learning rate is set in parameters\n",
    "# based on the number of epochs, the learning\n",
    "# rate will be changed. Initial epochs will use\n",
    "# base learning rate which will be exponentially\n",
    "# reduced for further epochs\n",
    "def lr_schedule(epoch):\n",
    "    if epoch < 15:\n",
    "        return base_learning_rate\n",
    "    if epoch < 25:\n",
    "        return 1e-1 * base_learning_rate\n",
    "    if epoch < 35:\n",
    "        return 1e-2 * base_learning_rate\n",
    "    return 1e-3 * base_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cff0a7-a623-4748-8040-c5ee905d2eb3",
   "metadata": {},
   "source": [
    "### Model with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722b23d-97a8-4e81-89d6-00658540ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Model with stop callback\n",
    "# Callbacks\n",
    "callbacks = [LearningRateScheduler(lr_schedule), \n",
    "             LearningRateWarmupCallback(initial_lr=base_learning_rate,\n",
    "                                        warmup_epochs=warmup_epochs,\n",
    "                                        verbose=verbose),\n",
    "             BroadcastGlobalVariablesCallback(0),\n",
    "             MetricAverageCallback(),\n",
    "             StopAtAccuracy(train_target=train_target, val_target=val_target, verbose=verbose)]\n",
    "\n",
    "# Append total time and save training data on local node\n",
    "if verbose:\n",
    "    callbacks.append(PrintTotalTime())\n",
    "\n",
    "    data_filepath = \"{}ranks-{}bs-{}lr-{}m-{}w-stop.csv\".format(hvd.size(), batch_size, base_learning_rate, momentum, warmup_epochs)\n",
    "\n",
    "    callbacks.append(SaveTrainingData(data_filepath=data_filepath))\n",
    "\n",
    "# Create model\n",
    "model = create_model(input_shape, base_learning_rate, momentum)\n",
    "model.summary()\n",
    "\n",
    "# Fit the model on the batches generated by datagen\n",
    "model.fit(train_iter,\n",
    "          callbacks=callbacks,\n",
    "          epochs=epochs,\n",
    "          verbose=verbose,\n",
    "          initial_epoch=0,\n",
    "          steps_per_epoch=len(train_iter) // hvd.size(),\n",
    "          validation_data=test_iter,\n",
    "          validation_steps=3 * len(test_iter) // hvd.size())\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(test_iter,\n",
    "                        steps=len(test_iter),\n",
    "                        verbose=verbose)\n",
    "\n",
    "# Save model\n",
    "model.save(savemodel)\n",
    "\n",
    "if verbose:\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0b895-b3bc-4d51-b101-ad3af001193c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "The above code is saved in a python file which is available at:\n",
    "<br>[classification_fruits360.py](https://github.com/drsaikirant88/drsaikirant88.github.io/blob/main/IBM%20Machine%20Learning/classification_fruits360.py)\n",
    "\n",
    "The code was executed using horovodrun with a list of servers and number of GPUs on each server\n",
    "The output is piped to a file\n",
    "<br>$ horovodrun -np 8 -H server1:4,server2:4 python classification_multigpu.py 2>&1 | tee output_fruits360\n",
    "\n",
    "Alternatively it can be run with mpirun\n",
    "<br>$ mpirun -np 4 python classification_multigpu.py 2>&1 | tee output_fruits360\n",
    "\n",
    "The training and validation accuracy target was set at 0.8. The stop at accuracy callback ensures that the model is able to achieve the target accuracy for two consequent epochs. Although the model crossed the training accuracy target after 8 epochs, the validation accuracy was achieved only after 16 epochs. The model was reinitialized and run for 50 epochs and showed similar performance. The test validation accuracy did not change significantly after 18 epochs and the maximum validation accuracy achieved was 0.87 using a batch size of 128, and a base learning rate of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680477a6-c761-4e23-ab05-f6e960a8b27a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
